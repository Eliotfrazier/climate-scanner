{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRODIGY RECIPES\n",
    "\n",
    "#### Idea: This notebook is to automate all the recipe generations including the paths and names of the datasets. \n",
    "\n",
    "#### Author: Vaishnavi Kandala\n",
    "\n",
    "#### Date: 7th Jan 2022\n",
    "\n",
    "#### Note: Each recipe components are rightly used before running the recipe. Ensure the right PORT is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the reference to all the categories in the dataset - currently we have around 73 categories.\n",
    "# path = \"/Users/vaishnavikandala/Desktop/Personal/Climate-Scanner/trends_&_innovation_classes.tsv\"\n",
    "# df_categories = pd.read_csv(path,sep=\"\\t\")\n",
    "# df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'capsule_wardrobe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def category_name_processing(category_name):\n",
    "    category_name = category_name.lower()\n",
    "    category_name = re.sub(\" \",\"_\",category_name)\n",
    "    category_name = re.sub(\"/\",\"_\",category_name)\n",
    "    category_name = re.sub(\"-\",\"_\",category_name)\n",
    "    return category_name\n",
    "\n",
    "category_name_processing(\"Capsule wardrobe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"/home/azureuser/christine/logs/\"\n",
    "patterns_path = \"/home/azureuser/christine/patterns/\"\n",
    "raw_data_path = \"/home/azureuser/christine/data/\"\n",
    "model_path = \"/home/azureuser/christine/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL CONFIG\n",
    "category_name = \"artificial intelligence\"\n",
    "category_name_processed = category_name_processing(category_name)\n",
    "\n",
    "### TASK1\n",
    "port_value_task1 = str(8084)\n",
    "task1_name = category_name_processed + \"_keywords\"\n",
    "seed_words = \"'artificial intelligence, machine learning, natural language processing, supervised learning, deep learning'\"\n",
    "task1_log = log_path + task1_name + \".out\"\n",
    "\n",
    "\n",
    "### TASK2\n",
    "port_value_task2 = str(8084)\n",
    "task2_name = category_name_processed + \"_sentences\"\n",
    "task2_data_path = raw_data_path + category_name_processed + \"_raw_data.jsonl\"\n",
    "task2_log = log_path + task2_name + \".out\"\n",
    "\n",
    "\n",
    "### TASK3\n",
    "port_value_task3 = str(8094)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/azureuser/christine/data/artificial_intelligence_raw_data.jsonl'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PORTS ASSIGNED\n",
    "\n",
    "PORT = 8084 path = http://51.132.188.89:8083/\n",
    "PORT = 8086 path = http://51.132.188.89:8085/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECIPE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 1 - RECIPE 1\n",
    "\n",
    "\n",
    "# Recipe 1 - This is mainly to get suggestions on the keywords relevant to a particular category. We are using a pre-trained model to get these suggestions (since, our categories are generic). We think we have good suggestions with this model but it can be further explored.\n",
    "\n",
    "# PRODIGY_PORT=8084 PRODIGY_CONFIG_OVERRIDES='{\"validate\": false}' nohup prodigy sense2vec.teach AI_Seed_Words model/s2v_old --seeds \"artificial intelligence, machine learning, natural language processing, supervised learning, deep learning\" > AIseedsOut.out 2>&1 &\n",
    "\n",
    "# Description:\n",
    "\n",
    "# PRODIGY_PORT - please use the specific port assigned to your task.\n",
    "# PRODIGY_CONFIG_OVERRIDES - to override any generic settings in the configuration. Here we do validate - false to ensure no input is missed because of formats.\n",
    "# sense2vec.tech - is the prodigy model or recipe\n",
    "# AI_Seed_Words - name of the dataset\n",
    "# models/s2v_old - is the selected model to generate embeddings.\n",
    "# seeds - seed words for the category\n",
    "# output location - AISeedsOut.out is the name of the output (log) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PRODIGY_PORT=8084 PRODIGY_CONFIG_OVERRIDES='{'validate': false}' nohup prodigy sense2vec.teach artificial_intelligence_keywords /home/azureuser/christine/model/s2v_old --seeds 'artificial intelligence, machine learning, natural language processing, supervised learning, deep learning' > /home/azureuser/christine/logs/artificial_intelligence_keywords.out 2>&1 &\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### RECIPE Generation\n",
    "\n",
    "\"PRODIGY_PORT=\" + port_value_task1  + \\\n",
    "\" PRODIGY_CONFIG_OVERRIDES='{\\'validate\\': false}'\" + \\\n",
    "\" nohup prodigy sense2vec.teach \" + task1_name + \\\n",
    "\" /home/azureuser/christine/model/s2v_reddit_2019_lg --seeds \" + seed_words + \" > \" + task1_log + \" 2>&1 &\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENERATE PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prodigy terms.to-patterns artificial_intelligence_keywords /home/azureuser/christine/patterns/artificial_intelligence_keywords.jsonl --label artificial_intelligence'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CONVERT SEED WORDS TO PATTERNS\n",
    "task1_patterns = patterns_path + task1_name + \".jsonl\"\n",
    "\n",
    "\"prodigy terms.to-patterns \" +  task1_name + \" \" + task1_patterns + \" --label \" + category_name_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECIPE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe 2 - This is mainly to train an initial model by selecting the sentences with the keywords (generated in the previous recipe). The more exhaustive keywords are a better model can be trained.\n",
    "\n",
    "#PRODIGY_PORT=8084 nohup prodigy textcat.teach AI_Words en_core_web_sm prodigyData/AI_TrainingData.jsonl --label \"Artificial Intelligence\" --patterns prodigyData/AI_Seed_Word_Patterns.jsonl > AIwordsOut.out 2>&1 &\n",
    "\n",
    "# Description:\n",
    "\n",
    "# PRODIGY_PORT - use the specific port for the task.\n",
    "# textcat.teach - prodigy recipe to train a base model\n",
    "# AI_Words - the name of the dataset\n",
    "# en_core_web_sm - model for embeddings\n",
    "# AI_TrainingData.jsonl - training data formatted in JSONL format (use the GitHub function to generate prodigy formatted dataset).\n",
    "# label - label for this call.\n",
    "# patterns - keywords generated using recipe 1 to further select specific category based sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PRODIGY_PORT=8084 PRODIGY_CONFIG_OVERRIDES='{'feed_overlap': false}' nohup prodigy textcat.teach artificial_intelligence_sentences en_core_web_sm /home/azureuser/christine/data/artificial_intelligence_raw_data.jsonl --label artificial_intelligence --patterns /home/azureuser/christine/patterns/artificial_intelligence_keywords.jsonl --exclude artificial_intelligence_sentences > /home/azureuser/christine/logs/artificial_intelligence_sentences.out 2>&1 &\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RECIPE GENERATION\n",
    "\"PRODIGY_PORT=\" + port_value_task2  + \\\n",
    "\" PRODIGY_CONFIG_OVERRIDES='{\\'feed_overlap\\': false}'\" + \\\n",
    "\" nohup prodigy textcat.teach \" +  task2_name + \\\n",
    "\" en_core_web_sm \"+ task2_data_path + \\\n",
    "\" --label \" + category_name_processed + \\\n",
    "\" --patterns \" + task1_patterns + \\\n",
    "\" --exclude \" + task2_name + \\\n",
    "\" > \" + task2_log + \" 2>&1 &\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECIPE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe 3 - This is mainly to retrain the model for that category using the annotations gathered using recipe 2.\n",
    "\n",
    "#PRODIGY_PORT=8084 prodigy train --textcat-multilabel AI_Words --label-stats --verbose --eval-split 0.2 model/AI-model\n",
    "\n",
    "# Description:\n",
    "\n",
    "# PRODIGY_PORT - use specific port for the task.\n",
    "# textcat_multilabel - retraining the model with the annotation data.\n",
    "# AI_Words - dataset used for annotations in recipe 2.\n",
    "# eval_split - 80% train 20% test.\n",
    "# AI-model - model used.\n",
    "# This recipe will give the performance Precision / Recall / F-Score for the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prodigy train --textcat-multilabel artificial_intelligence_sentences --label-stats --verbose --eval-split 0.2 /home/azureuser/christine/model/artificial_intelligence_model'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3_model_path = model_path + category_name_processed + \"_model\"\n",
    "\n",
    "\"prodigy train --textcat-multilabel \" + \\\n",
    "task2_name + \" --label-stats --verbose --eval-split 0.2 \" + \\\n",
    "task3_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
